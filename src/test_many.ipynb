{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import github_client\n",
    "\n",
    "def build_evaluation_suite(repo_full_name: str, state: str = 'open', limit: int = 10):\n",
    "    print(f\"Building evaluation suite for {repo_full_name} with PRs in state {state}\")\n",
    "    repo = github_client.get_repo(repo_full_name)\n",
    "\n",
    "    pr_numbers = []\n",
    "    \n",
    "    for i, pr in enumerate(repo.get_pulls(state=state)):\n",
    "        if pr.user.login == \"github-actions[bot]\":\n",
    "            continue\n",
    "\n",
    "        print(f\"\\tPR #{pr.number}, {pr.user.login}: {pr.title}\")\n",
    "        pr_numbers.append(pr.number)\n",
    "\n",
    "        if i >= limit:\n",
    "            print(f\"\\tReached limit of {limit} PRs\")\n",
    "            break\n",
    "\n",
    "    print(\"\\tExample config: {}\\n\".format({\n",
    "        repo_full_name: pr_numbers\n",
    "    }))\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "# build_evaluation_suite(\"locustio/locust\")\n",
    "# build_evaluation_suite(\"pandas-dev/pandas\")\n",
    "# build_evaluation_suite(\"ktrnka/update-your-readme\", state='closed', limit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "def diff_readmes(original_readme: str, updated_readme: str):\n",
    "    diff = difflib.unified_diff(\n",
    "        original_readme.splitlines(),\n",
    "        updated_readme.splitlines(),\n",
    "    )\n",
    "    lines_added = 0\n",
    "    lines_removed = 0\n",
    "    for line in diff:\n",
    "        if line.startswith('+') and not line.startswith('+++'):\n",
    "            lines_added += 1\n",
    "        elif line.startswith('-') and not line.startswith('---'):\n",
    "            lines_removed += 1\n",
    "    return lines_added, lines_removed\n",
    "\n",
    "# Test\n",
    "\n",
    "diff_readmes(\"Hello\\nWorld\", \"Hello\\nWorld\\nGoodbye\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_test_suite = {\n",
    "    'locustio/locust': [2899, 2856, 2820, 2786],\n",
    "    'ktrnka/update-your-readme': [50, 49, 46, 44, 43, 41, 40],\n",
    "}\n",
    "\n",
    "small_test_suite = {\n",
    "    'ktrnka/update-your-readme': [41, 40],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing locustio/locust...\n",
      "\tTesting PR #2899...\n",
      "\tTesting PR #2856...\n",
      "\tTesting PR #2820...\n",
      "\tTesting PR #2786...\n",
      "Testing ktrnka/update-your-readme...\n",
      "\tTesting PR #50...\n",
      "\tTesting PR #49...\n",
      "\tTesting PR #46...\n",
      "\tTesting PR #44...\n",
      "\tTesting PR #43...\n",
      "\tTesting PR #41...\n",
      "\tTesting PR #40...\n",
      "\n",
      "Tested against 11 PRs in 2 repos.\n",
      "\n",
      "36% failed.\n",
      "Total runtime: 99s\n",
      "Mean runtime per PR: 9s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple, Optional, Tuple\n",
    "from core import ReadmeRecommendation, review_pull_request\n",
    "from time import time\n",
    "\n",
    "class SingleOutcome(NamedTuple):\n",
    "    result: Optional[ReadmeRecommendation]\n",
    "    error: Optional[ValueError]\n",
    "    seconds: float\n",
    "    diff: Optional[Tuple]\n",
    "\n",
    "test_suite = medium_test_suite\n",
    "\n",
    "outcomes = {}\n",
    "for repo_name, pr_numbers in test_suite.items():\n",
    "    print(f\"Testing {repo_name}...\")\n",
    "    for pr_number in pr_numbers:\n",
    "        print(f\"\\tTesting PR #{pr_number}...\")\n",
    "\n",
    "\n",
    "        start_time = time()\n",
    "\n",
    "        try:\n",
    "            repo = github_client.get_repo(repo_name)\n",
    "            pr = repo.get_pull(pr_number)\n",
    "\n",
    "            # Get the base README\n",
    "            base_readme = repo.get_contents(\"README.md\", ref=pr.base.sha).decoded_content.decode()\n",
    "\n",
    "            result = review_pull_request(repo, pr)\n",
    "\n",
    "            diff_results = None\n",
    "            if result.should_update:\n",
    "                diff_results = diff_readmes(base_readme, result.updated_readme)\n",
    "\n",
    "            outcomes[(repo_name, pr_number)] = SingleOutcome(result, None, time() - start_time, diff_results)\n",
    "        except ValueError as e:\n",
    "            outcomes[(repo_name, pr_number)] = SingleOutcome(None, e, time() - start_time, None)\n",
    "\n",
    "# summarize the results\n",
    "percent_failed = len([outcome for outcome in outcomes.values() if outcome.result is None]) / len(outcomes)\n",
    "total_runtime = sum(outcome.seconds for outcome in outcomes.values())\n",
    "mean_runtime = total_runtime / len(outcomes)\n",
    "\n",
    "print(f\"\"\"\n",
    "Tested against {len(outcomes)} PRs in {len(test_suite)} repos.\n",
    "\n",
    "{percent_failed:.0%} failed.\n",
    "Total runtime: {total_runtime:.0f}s\n",
    "Mean runtime per PR: {mean_runtime:.0f}s\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('locustio/locust', 2856): None in 12s\n",
      "\tError: 1 validation error for ReadmeRecommendation\n",
      "  Value error, updated_readme must be provided if should_update is True [type=value_error, input_value={'should_update': True, '...r direction for users.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/value_error\n",
      "('locustio/locust', 2786): None in 12s\n",
      "\tError: 1 validation error for ReadmeRecommendation\n",
      "  Value error, updated_readme must be provided if should_update is True [type=value_error, input_value={'should_update': True, '...ion these new options.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/value_error\n",
      "('ktrnka/update-your-readme', 50): None in 10s\n",
      "\tError: 1 validation error for ReadmeRecommendation\n",
      "  Value error, updated_readme must be provided if should_update is True [type=value_error, input_value={'should_update': True, '...tructure and features.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/value_error\n",
      "('ktrnka/update-your-readme', 43): None in 10s\n",
      "\tError: 1 validation error for ReadmeRecommendation\n",
      "  Value error, updated_readme must be provided if should_update is True [type=value_error, input_value={'should_update': True, '...nd visually appealing.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/value_error\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Review errors\n",
    "for outcome_id, outcome in outcomes.items():\n",
    "    if outcome.error:\n",
    "        print(f\"{outcome_id}: {outcome.result} in {outcome.seconds:.0f}s\")\n",
    "        print(f\"\\tError: {outcome.error}\")\n",
    "    # if outcome.diff:\n",
    "    #     print(f\"\\tDiff: {outcome.diff}\")\n",
    "# pprint(outcomes[('ktrnka/update-your-readme', 41)].error.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ('locustio/locust', 2899)\n",
      "Should update? False in 4s\n",
      "\n",
      "\n",
      "# ('locustio/locust', 2820)\n",
      "Should update? False in 4s\n",
      "\n",
      "\n",
      "# ('ktrnka/update-your-readme', 49)\n",
      "Should update? True in 8s\n",
      "\n",
      "Reason: The pull request includes a change to the core.py file, which is part of the project structure. This change should be reflected in the README to keep it up-to-date and accurate.\n",
      "Diff: +0, -0\n",
      "\n",
      "# ('ktrnka/update-your-readme', 46)\n",
      "Should update? True in 10s\n",
      "\n",
      "Reason: The existing README could be improved with some additional details and formatting to enhance readability and usability. The pull request changes indicate that the project structure and GitHub Actions workflows have been updated, which should be reflected in the README.\n",
      "Diff: +0, -0\n",
      "\n",
      "# ('ktrnka/update-your-readme', 44)\n",
      "Should update? True in 8s\n",
      "\n",
      "Reason: The README should be updated to reflect the new changes, including the addition of the `main.py` file in the `src` directory.\n",
      "Diff: +2, -1\n",
      "Updated README: \n",
      "# Update Your README\n",
      "\n",
      "This project automatically updates README files based on changes in pull requests using GitHub API and language models.\n",
      "\n",
      "## Features\n",
      "\n",
      "- Analyzes pull requests for changes\n",
      "- Suggests README updates based on new dependencies and project structure\n",
      "- Uses LangChain and Anthropic's Claude model for intelligent suggestions\n",
      "- Provides informative logging output about update actions\n",
      "- Option to skip README checks for testing purposes\n",
      "- Automatically closes stale README PRs\n",
      "\n",
      "## Prerequisites\n",
      "\n",
      "- GitHub repository\n",
      "- GitHub API token\n",
      "- Anthropic API key\n",
      "\n",
      "## Usage\n",
      "\n",
      "To use this action in your GitHub workflow, add the following step to your `.github/workflows/your-workflow.yml` file, replacing the version as needed:\n",
      "\n",
      "```yaml\n",
      "- uses: ktrnka/update-your-readme@v1\n",
      "  with:\n",
      "    github-token: ${{ secrets.GITHUB_TOKEN }}\n",
      "    anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}\n",
      "    repository: ${{ github.repository }}\n",
      "    pull-request-number: ${{ github.event.pull_request.number }}\n",
      "    readme-file: README.md\n",
      "```\n",
      "\n",
      "Make sure to set up the `ANTHROPIC_API_KEY` secret in your repository settings. Under your repo settings, under Actions > General be sure to check \"Allow GitHub Actions to create and approve pull requests\" and allow read/write from Github Actions.\n",
      "\n",
      "### Skipping README Check\n",
      "\n",
      "To skip the README check for testing purposes, include \"NO README REVIEW\" in the pull request body. This will cause the action to exit without performing any updates.\n",
      "\n",
      "## Project Structure\n",
      "\n",
      "```\n",
      ".\n",
      "├── .github\n",
      "│   └── workflows\n",
      "│       ├── suggest_readme_updates.yml\n",
      "│       └── close_stale_prs.yml\n",
      "├── src\n",
      "│   ├── core.py\n",
      "│   ├── close_stale_prs.sh\n",
      "│   ├── test_github.ipynb\n",
      "│   ├── test_popular_repos.ipynb\n",
      "│   └── main.py\n",
      "├── .gitignore\n",
      "├── NOTES.md\n",
      "├── Pipfile\n",
      "├── Pipfile.lock\n",
      "├── README.md\n",
      "└── action.yml\n",
      "```\n",
      "\n",
      "## Contributing\n",
      "\n",
      "Contributions are welcome! Please feel free to submit a Pull Request.\n",
      "\n",
      "## License\n",
      "\n",
      "[MIT License](https://opensource.org/licenses/MIT)\n",
      "\n",
      "## GitHub Actions Integration\n",
      "\n",
      "This project includes GitHub Actions workflows that enhance the README update process:\n",
      "\n",
      "1. **Suggest README Updates**: Defined in `.github/workflows/suggest_readme_updates.yml`, this workflow:\n",
      "   - Uses the `ktrnka/update-your-readme@use_marketplace_action` action\n",
      "   - Runs the README update process\n",
      "   - Creates a new pull request with the suggested changes\n",
      "   - Adds a comment to the original pull request with a link to the suggested changes\n",
      "\n",
      "2. **Close Stale README PRs**: Defined in `.github/workflows/close_stale_prs.yml`, this workflow:\n",
      "   - Triggers when a pull request is closed\n",
      "   - Runs a shell script to identify and close any stale README update PRs associated with the closed PR\n",
      "\n",
      "To use these features, ensure that your repository has the necessary secrets set up (`GITHUB_TOKEN` and `ANTHROPIC_API_KEY`).\n",
      "\n",
      "### Closing Stale README PRs\n",
      "\n",
      "The `close_stale_prs.sh` script in the `src` directory is used to automatically close stale README PRs. It:\n",
      "- Identifies open pull requests with the \"automated pr\" label\n",
      "- Closes PRs whose branch names match the pattern related to the closed parent PR\n",
      "- Adds a comment explaining why the PR was closed\n",
      "\n",
      "This helps keep the repository clean by removing outdated README update suggestions.\n",
      "\n",
      "Note: The GitHub Actions workflows respect the \"NO README REVIEW\" flag in pull request bodies, allowing for skipping README checks when needed.\n",
      "\n",
      "# ('ktrnka/update-your-readme', 41)\n",
      "Should update? True in 11s\n",
      "\n",
      "Reason: The pull request has made changes to the project structure, dependencies, and GitHub Actions integration. These changes should be reflected in the README to ensure it provides up-to-date information for users.\n",
      "Diff: +0, -0\n",
      "\n",
      "# ('ktrnka/update-your-readme', 40)\n",
      "Should update? True in 9s\n",
      "\n",
      "Reason: The proposed changes in the pull request seem to have introduced new functionality or dependencies that are not currently reflected in the README. An update to the README would help ensure users have accurate information about the project's features, setup, and usage.\n",
      "Diff: +0, -0\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Review non-errors\n",
    "for outcome_id, outcome in outcomes.items():\n",
    "    if outcome.result:\n",
    "        print(f\"\"\"\n",
    "# {outcome_id}\n",
    "Should update? {outcome.result.should_update} in {outcome.seconds:.0f}s\n",
    "\"\"\")\n",
    "        if outcome.result.should_update:\n",
    "            print(f\"\"\"Reason: {outcome.result.reason}\\nDiff: +{outcome.diff[0]}, -{outcome.diff[1]}\"\"\")\n",
    "            if sum(outcome.diff) > 0:\n",
    "                print(f\"\"\"Updated README: \\n{outcome.result.updated_readme}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday afternoon\n",
    "\n",
    "I learned the hard way that something about the ChatPromptTemplate was disabling the Python variables in the Human step,\n",
    "so it was generating the readme purely from guidelines\n",
    "\n",
    "## After the fix:\n",
    "\n",
    "    Tested against 11 PRs in 2 repos.\n",
    "\n",
    "    36% failed.\n",
    "    Total runtime: 91s\n",
    "    Mean runtime per PR: 8s\n",
    "\n",
    "The failed cases are doing should_update=True and updated_readme = nothing. I saw in the raw output that one of the really bad subtractions just had [rest of readme the same] or some such at the bottom.\n",
    "\n",
    "I'm going to re-run this to be sure:\n",
    "\n",
    "\n",
    "# Dev log: Monday\n",
    "\n",
    "Refactor:\n",
    "- More controlled experiment (multiple repos, build a fixed set of PRs ahead of time)\n",
    "- Track failure rate and execution time\n",
    "- Hold onto any objects to adhoc analysis after running\n",
    "\n",
    "Test suites:\n",
    "\n",
    "    medium_test_suite = {\n",
    "        'locustio/locust': [2899, 2856, 2820, 2786],\n",
    "        'ktrnka/update-your-readme': [50, 49, 46, 44, 43, 41, 40],\n",
    "    }\n",
    "\n",
    "    small_test_suite = {\n",
    "        'ktrnka/update-your-readme': [41, 40],\n",
    "    }\n",
    "\n",
    "## Medium test suite\n",
    "\n",
    "### Baseline with Haiku, before removing the directory tree\n",
    "\n",
    "    Tested against 11 PRs in 2 repos.\n",
    "\n",
    "    18% failed.\n",
    "    Total runtime: 135s\n",
    "    Mean runtime per PR: 12s\n",
    "\n",
    "### After removing the directory tree\n",
    "\n",
    "    Tested against 11 PRs in 2 repos.\n",
    "\n",
    "    18% failed.\n",
    "    Total runtime: 129s\n",
    "    Mean runtime per PR: 12s\n",
    "\n",
    "It's slightly faster but not a lot. I'll keep the change though.\n",
    "\n",
    "### Adding prompt caching\n",
    "\n",
    "    Tested against 11 PRs in 2 repos.\n",
    "\n",
    "    0% failed.\n",
    "    Total runtime: 54s\n",
    "    Mean runtime per PR: 5s\n",
    "\n",
    "Notes\n",
    "- It throws an annoying warning \"extra_headers was transferred to model_kwargs\" but that's what the docs show: https://api.python.langchain.com/en/latest/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html\n",
    "- The speedup is wonderful! That's what I'd hoped for\n",
    "- The 0% failure rate is surprising. It's possible that it's a result of needing to refactor to use the SystemMessage vs HumanMessage\n",
    "\n",
    "I'm going to re-run this without any changes cause I kind of don't even believe that we have no errors now:\n",
    "\n",
    "    Tested against 11 PRs in 2 repos.\n",
    "\n",
    "    0% failed.\n",
    "    Total runtime: 53s\n",
    "    Mean runtime per PR: 5s\n",
    "\n",
    "Huh\n",
    "\n",
    "## Small test suite\n",
    "\n",
    "### Baseline test\n",
    "\n",
    "    Tested against 2 PRs in 1 repos.\n",
    "\n",
    "    50% failed.\n",
    "    Total runtime: 55s\n",
    "    Mean runtime per PR: 28s\n",
    "\n",
    "### With Claude 3 Haiku\n",
    "\n",
    "    Tested against 2 PRs in 1 repos.\n",
    "\n",
    "    0% failed.\n",
    "    Total runtime: 22s\n",
    "    Mean runtime per PR: 11s\n",
    "\n",
    "\n",
    "\n",
    "# Dev log: Sunday\n",
    "\n",
    "## Before prompt engineering, running on Locust\n",
    "Counter({'ValidationError': 3, 'should_update': 1})\n",
    "\n",
    "## Stronger guidance in the prompt itself, like the Pydantic field descriptions and how they're mentioned in the prompt itself\n",
    "Counter({'ValidationError': 4})\n",
    "Counter({'ValidationError': 4})\n",
    "Counter({'ValidationError': 2, 'should_update': 1, 'no_update': 1})\n",
    "\n",
    "## Retries\n",
    "Counter({'ValidationError': 3, 'should_update': 1})\n",
    "\n",
    "## Prompt updates, Pydantic model updates\n",
    "Counter({'should_update': 3, 'ValueError': 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "update-your-readme-LRwUm5rQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
